{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mariavarg/fast-stable-diffusion/blob/main/Copy_of_cagliostro_colab_ui.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "![](https://visitor-badge.glitch.me/badge?page_id=linaqruf.cag-webui) [![GitHub](https://badgen.net/badge/icon/github?icon=github&label)](https://github.com/Linaqruf/sd-notebook-collection/blob/main/cagliostro-colab-ui.ipynb) [![](https://dcbadge.vercel.app/api/shield/850007095775723532?style=flat)](https://lookup.guru/850007095775723532) [![ko-fi](https://img.shields.io/badge/Support%20me%20on%20Ko--fi-F16061?logo=ko-fi&logoColor=white&style=flat)](https://ko-fi.com/linaqruf) <a href=\"https://saweria.co/linaqruf\"><img alt=\"Saweria\" src=\"https://img.shields.io/badge/Saweria-7B3F00?style=flat&logo=ko-fi&logoColor=white\"/></a> \n",
        "\n",
        "# **Cagliostro Colab UI**\n",
        "All-in-One, Customizable and Flexible AUTOMATIC1111's Stable Diffusion Web UI for Google Colab. <br>\n",
        "\n",
        "<details>\n",
        "  <summary><big>Credits</big></summary>\n",
        "    This colab notebook was heavily inspired by:\n",
        "    <ul>\n",
        "      <li><a href=\"https://colab.research.google.com/drive/1wEa-tS10h4LlDykd87TF5zzpXIIQoCmq\">Nocrypt's Colab Remastered</a></li>\n",
        "      <li><a href=\"https://colab.research.google.com/github/acheong08/Diffusion-ColabUI/blob/main/Diffusion_WebUI.ipynb\">Acheong's Diffusion Web UI</a></li>\n",
        "      <li><a href=\"https://colab.research.google.com/github/TheLastBen/fast-stable-diffusion/blob/main/fast_stable_diffusion_AUTOMATIC1111.ipynb\">TheLastBen's Fast Stable Diffusion</a></li>\n",
        "    </ul>\n",
        "</details>\n",
        "\n",
        "<details>\n",
        "  <summary><big>What's New?</big></summary>\n",
        "  <br>\n",
        " <font color=gray>v.2.0.1 (27/03/23)</font>\n",
        "  <ul>\n",
        "    <li>Clean install and update Web UI to latest version, commit hash : <code>955df7751eef11bb7697e2d77f6b8a6226b21e13</code></li>\n",
        "    <li>Manually edit <code>config.json</code> and <code>ui-config.json</code></li>\n",
        "    <li>Change <code>auto_model</code> and <code>auto_vae</code> logic, change <code>config.json</code> instead of using <code>--vae_path</code> and <code>--ckpt</code> </li>\n",
        "  </ul>\n",
        "  <br>\n",
        " <font color=gray>v.2.0.0 (27/03/23)</font>\n",
        "  <ul>\n",
        "    <li>Reformat notebook with <a href=\"https://github.com/psf/black\">black python formatter</a></li>\n",
        "    <li>Update Web UI and all extensions version (not latest)</li>\n",
        "    <li>Downgrade <code>xformers</code> to <code>0.0.16</code></li>\n",
        "    <li>Downgrade <code>triton</code> to <code>2.0.0</code></li>\n",
        "    <li>Set both <code>lora_dir</code> and<code>additional_networks_extra_lora_path</code> path to <code>os.path.join(repo_dir, \"models/Lora\")</code></li>\n",
        "    <li>Set <code>lora_dir</code> path to <code>os.path.join(repo_dir, \"models/ControlNet\")</code></li>\n",
        "    <li>Reset Anapnoe UI commit hash to <code>802fb8a16ba4bdbfba0dca55f9cdb265f4bd86f2</code></li>\n",
        "    <li>Force reset commit hash to <code>3b47b000199ea8baf724080936ef985f53b3d081</code> when <code>use_anapnoe_ui</code> is enabled</li>\n",
        "    <li>Added <code>mount_drive</code> function</code></li>\n",
        "    <li>Added more error handling</li>\n",
        "    <li>Set some environment variables:</li>\n",
        "            <ul>\n",
        "            <li>os.environ['colab_url'] = eval_js(\"google.colab.kernel.proxyPort(7860, {'cache': false})\")</li>\n",
        "            <li>os.environ[\"LD_PRELOAD\"] = \"libtcmalloc.so\"</li>\n",
        "            <li>os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"3\"</li>\n",
        "            <li>os.environ[\"SAFETENSORS_FAST_GPU\"]= '1'</li>\n",
        "        </ul>\n",
        "    <li>Added 3 new default model</li>\n",
        "        <ul>\n",
        "            <li><a href=\"https://huggingface.co/Linaqruf/anything-v3.0\">Anything V3.0</a></li>\n",
        "            <li><a href=\"https://huggingface.co/Lykon/AnyLoRA\">AnyLoRA</a></li>\n",
        "            <li><a href=\"https://huggingface.co/Lykon/AnimePastelDream\">Anime Pastel Dream</a></li>\n",
        "        </ul>\n",
        "    <li>Deleted 3 default model</li>\n",
        "        <ul>\n",
        "            <li>Anything V3.2</li>\n",
        "            <li>Anything V3.3</li>\n",
        "            <li>HoloKuki V2</li>\n",
        "        </ul>\n",
        "    <li>Changed <code>Chillout-Mix</code> to <code>Chillout-Mix-Ni</code></li>\n",
        "    <li>Changed <code>Illuminati V1.1</code> download link from CivitAI to Huggingface</li>\n",
        "    <li>Put all ControlNet things to new separated cell</li>\n",
        "         <ul>\n",
        "            <li>Added <code>pre_download_annotator</code> back</li>\n",
        "            <li>Added <code>sd21_control_model</code></li>\n",
        "            <li>Added <code>wd15_control_model</code></li>\n",
        "            <li>Added option to change ControlNet model and Adapter config outside Web UI</li>\n",
        "        </ul>\n",
        "    <li>Added support for load custom url from Google Drive, tricky, by copying from Google Drive to destination path.</li>\n",
        "    <li>Set <code>--multiple</code> as default alternative tunnels, please don't use Gradio URL at the moment</li>\n",
        "         <ul>\n",
        "            <li>Recommended Tunnels:</code></li>\n",
        "            <li><code>ngrok</code> > <code>cloudflared</code> > <code>remotemoe</code> > <code>localhostrun</code> > <code>googleusercontent</code> > <code>gradio</code></li>\n",
        "        </ul>    \n",
        "  </ul>\n",
        "  <br> \n",
        "<font color=gray>v.1.4.1 (11/03/23)</font>\n",
        "  <ul>\n",
        "    <li>Trying to establish my own style, deleted all possible NoCrypt and TheLastBen's code legacy</li>\n",
        "    <li>Temporary removed <code>pre_download_annotator</code></li>\n",
        "    <li>Deleted <code>PastelMix</code> from available models because the model license sold to <a href=\"https://fantasy.ai/\">fantasy.ai</a></li>\n",
        "    <li>Deleted <code>RefSlave-V2</code> from available models because the author removed his model from huggingface and civitai</li>\n",
        "    <li>Added HoloKuki V2 as to available models</li>\n",
        "    <li>Update t2i adapter model, currently has 8 model</li>\n",
        "  </ul>\n",
        "  <br>\n",
        "<font color=gray>v.1.4 (09/03/23)</font>\n",
        "  <ul>\n",
        "    <li>Update xformers pre-compiled wheels to <code>xFormers 0.0.17.dev466</code></li>\n",
        "    <li>Update pre-installed dependencies for <code>Python 3.9.16</code></li>\n",
        "    <li>Added new Stable Diffusion Web UI Extensions: <code>batchlinks-webui</code> and <code>sd-webui-llul</code></li>\n",
        "  </ul>\n",
        "  <br>\n",
        "<font color=gray>v.1.3 (01/03/23)</font>\n",
        "  <ul>\n",
        "    <li>Added an option to save outputs to drive.</li>\n",
        "    <li>Moved support button to separated and hidden section, because it looks ugly.</li>\n",
        "    <li>Fixed some bugs where VAE can't be changed in webui.</li>\n",
        "    <li>Updated dependencies, webui, and extensions to the latest version.</li>\n",
        "    <li>Deleted <code>hitokomoru_v1_5</code>.</li>\n",
        "    <li>Added <a href=\"https://huggingface.co/waifu-diffusion/wd-1-5-beta2\">WD 1.5 Beta 2 - Aesthetic</a>. Releases note: <a href=\"https://cafeai.notion.site/WD-1-5-Beta-2-Release-Notes-2852db5a9cdd456ba52fc5730b91acfd\">here</a></li>\n",
        "    <li>Added <code>illuminati_diffusion_v1_1</code>. Required embeddings coming soon. </li>\n",
        "    <li>Added <code>ref_slave_v2</code> and set it to default</li>    \n",
        "    <li>Used <code>git reset</code> to move the head to <code>3cd625854f9dc71235a432703ba82abfc5d1a3fc</code> when <code>try_new_ui_ux</code> set to True, as it's a stable commit history for now.</li>\n",
        "    <li>Added <code>t2iadapter_sketch-fp16.safetensors</code> to t2iadapter model list.</li>\n",
        "  </ul>\n",
        "  <br>\n",
        "<font color=gray>v.1.2.2 (23/02/23)</font>\n",
        "  <ul>\n",
        "    <li>Added <b>Extra</b> section for optional cell, the first cell added to the section is <b>Download Generated Images V2</b>, to store your output to huggingface and download it.</li>\n",
        "    <li>Changed how the installation works. If the folder exists, then skip unpacking.</li>\n",
        "    <li>Added <code>Replicant V1.0</code> as default model.</li>\n",
        "    <li>Added new UI/UX theme from <a href \"https://github.com/anapnoe/stable-diffusion-webui\">Anapnoe</a>. <code>[Experimental]</code> </li>\n",
        "    <li>Added support for <code>multi-controlnet</code> by including a slider in certain cells (default value: <code>2</code>).</li>\n",
        "    <li>Backed up all ControlNet annotator and model data to a personal repository.</li>\n",
        "  </ul>\n",
        "  <br>\n",
        "<font color=gray>v.1.2.1 (21/02/23)</font>\n",
        "  <ul>\n",
        "    <li>Added <code>tqdm</code> to track installation, unpacking, and download progress since original logs are disabled.</li>\n",
        "    <li>Pulled the latest version of the repository and built-in extensions.</li>\n",
        "    <li>Pre-downloaded ControlNet annotator/preprocessor.</li>\n",
        "    <li>Added T2I Adapter model from TencentArc.</li>\n",
        "    <li>Added several good custom upscalers such as <code>4x-Animesharp</code>, <code>4x-UltraSharp</code>, <code>Lollypop</code>, and others.</li>\n",
        "    <li>Added Video Loopback extension for creating videos in Img2img, now with ControlNet support.</li>\n",
        "    <li>Deleted CivitAI browser extension because another extension called <code>sd-filer</code> serves the same purpose. You can download models, lora, and embeddings from the web UI.</li>\n",
        "    <li>Added Katanuki extension to convert results to transparent images.</li>\n",
        "    <li>Deleted Haku Img Extensions because they were rarely used.</li>\n",
        "    <li>Added 'Use Old Karras Scheduler' option to quick settings (header).</li>\n",
        "    <li>Fixed an invalid URL for Chillout Mix Pruned and SD 1.5 Pruned.</li>\n",
        "    <li>Fixed the 'Download Generated Images' cell when creating a duplicate zip from 'output.zip(1)' to 'output(n+1).zip'.</li>\n",
        "    <li>Added checkboxes for randomly selecting VAE and Model.</li>\n",
        "  </ul>\n",
        "</details>\n"
      ],
      "metadata": {
        "id": "WgQr3s96015a"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "HgNPnQeNC8YA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title ## **Install Stable Diffusion Web UI**\n",
        "import os\n",
        "import shutil\n",
        "import zipfile\n",
        "import time\n",
        "import json\n",
        "from google.colab.output import eval_js\n",
        "from google.colab import drive\n",
        "from datetime import timedelta\n",
        "from subprocess import getoutput\n",
        "from IPython.display import clear_output, display, HTML\n",
        "from IPython.utils import capture\n",
        "from tqdm import tqdm\n",
        "\n",
        "%store -r\n",
        "\n",
        "# root directory\n",
        "root_dir = \"/content\"\n",
        "repo_dir = os.path.join(root_dir, \"stable-diffusion-webui\")\n",
        "tmp_dir = os.path.join(root_dir, \"tmp\")\n",
        "patches_dir = os.path.join(root_dir, \"patches\")\n",
        "deps_dir = os.path.join(root_dir, \"deps\")\n",
        "\n",
        "# repository directory\n",
        "outputs_dir = os.path.join(repo_dir, \"outputs\")\n",
        "components_dir = os.path.join(repo_dir, \"models/components\")\n",
        "models_dir = os.path.join(repo_dir, \"models/Stable-diffusion\")\n",
        "vaes_dir = os.path.join(repo_dir, \"models/VAE\")\n",
        "esrgan_dir = os.path.join(repo_dir, \"models/ESRGAN/\")\n",
        "hypernetworks_dir = os.path.join(repo_dir, \"models/hypernetworks\")\n",
        "embeddings_dir = os.path.join(repo_dir, \"embeddings\")\n",
        "extensions_dir = os.path.join(repo_dir, \"extensions\")\n",
        "lora_dir = os.path.join(repo_dir, \"models/Lora\")\n",
        "control_dir = os.path.join(repo_dir, \"models/ControlNet\")\n",
        "\n",
        "# extensions directory\n",
        "annotator_dir = os.path.join(extensions_dir, \"sd-webui-controlnet/annotator\")\n",
        "\n",
        "with capture.capture_output() as cap:\n",
        "    for dir in [\n",
        "        \"root_dir\",\n",
        "        \"repo_dir\",\n",
        "        \"tmp_dir\",\n",
        "        \"outputs_dir\",\n",
        "        \"components_dir\",\n",
        "        \"models_dir\",\n",
        "        \"vaes_dir\",\n",
        "        \"esrgan_dir\",\n",
        "        \"hypernetworks_dir\",\n",
        "        \"embeddings_dir\",\n",
        "        \"extensions_dir\",\n",
        "        \"lora_dir\",\n",
        "        \"control_dir\",\n",
        "        \"annotator_dir\",\n",
        "    ]:\n",
        "        %store {dir}\n",
        "    del cap\n",
        "\n",
        "os.makedirs(patches_dir, exist_ok=True)\n",
        "os.makedirs(deps_dir, exist_ok=True)\n",
        "\n",
        "# url or path\n",
        "config_file = os.path.join(repo_dir, \"config.json\")\n",
        "\n",
        "# @markdown ### Anapnoe UI/UX Config\n",
        "use_anapnoe_ui = True  # @param {type:'boolean'}\n",
        "\n",
        "ui_commit_hash = \"802fb8a16ba4bdbfba0dca55f9cdb265f4bd86f2\"  # @param {type:'string'}\n",
        "stable_commit_hash = \"3b47b000199ea8baf724080936ef985f53b3d081\"\n",
        "\n",
        "# @markdown ### Drive Config\n",
        "mount_drive = True  # @param {type:'boolean'}\n",
        "output_to_drive = True  # @param {type:'boolean'}\n",
        "# @markdown ### Repo Config\n",
        "\n",
        "commit_hash = \"955df7751eef11bb7697e2d77f6b8a6226b21e13\"  # @param {type:'string'}\n",
        "git_pull = True  # @param {type:'boolean'}\n",
        "clean_install = False  # @param {type:'boolean'}\n",
        "load_v2_in_vram = True  # @param {type:'boolean'}\n",
        "merge_in_vram = True  # @param {type:'boolean'}\n",
        "colab_optimizations = True  # @param {type:'boolean'}\n",
        "\n",
        "# @markdown ### Built-In Extensions Config\n",
        "update_extensions = True  # @param {type:'boolean'}\n",
        "\n",
        "# model\n",
        "os.chdir(root_dir)\n",
        "\n",
        "package_url = [\n",
        "    \"https://huggingface.co/Linaqruf/fast-repo/resolve/main/webui.tar.lz4\",\n",
        "    \"https://huggingface.co/Linaqruf/fast-repo/resolve/main/webui-deps.tar.lz4\",\n",
        "    \"https://huggingface.co/Linaqruf/fast-repo/resolve/main/webui-cache.tar.lz4\",\n",
        "]\n",
        "\n",
        "\n",
        "def ubuntu_deps(url, name, dst):\n",
        "    os.makedirs(dst, exist_ok=True)\n",
        "    !wget -q --show-progress {url}\n",
        "    with zipfile.ZipFile(name, \"r\") as deps:\n",
        "        deps.extractall(dst)\n",
        "    !dpkg -i {dst}/*\n",
        "    os.remove(name)\n",
        "    shutil.rmtree(dst)\n",
        "\n",
        "\n",
        "def pre_download():\n",
        "    for package in tqdm(package_url, desc=\"\u001b[1;32mUnpacking WebUI\"):\n",
        "        with capture.capture_output() as cap:\n",
        "            package_name = os.path.basename(package)\n",
        "            !aria2c --console-log-level=error --summary-interval=10 -c -x 16 -k 1M -s 16 -d {root_dir} -o {package_name} {package}\n",
        "            if package_name == \"webui-deps.tar.lz4\":\n",
        "                !tar -xI lz4 -f {package_name} --overwrite-dir --directory=/usr/local/lib/python3.9/dist-packages/\n",
        "            else:\n",
        "                !tar -xI lz4 -f {package_name} --directory=/\n",
        "            os.remove(package_name)\n",
        "            del cap\n",
        "\n",
        "    if os.path.exists(\"/usr/local/lib/python3.9/dist-packages/ffmpy-0.3.0.dist-info\"):\n",
        "        shutil.rmtree(\"/usr/local/lib/python3.9/dist-packages/ffmpy-0.3.0.dist-info\")\n",
        "\n",
        "    s = getoutput(\"nvidia-smi\")\n",
        "    with capture.capture_output() as cap:\n",
        "        if not \"T4\" in s:\n",
        "            !pip uninstall -y xformers\n",
        "            !pip install -q xformers triton\n",
        "        del cap\n",
        "\n",
        "    !git config --global user.email \"you@example.com\"\n",
        "    !git config --global user.name \"Your Name\"\n",
        "\n",
        "\n",
        "def read_config(filename):\n",
        "    with open(filename, \"r\") as f:\n",
        "        config = json.load(f)\n",
        "    return config\n",
        "\n",
        "\n",
        "def write_config(filename, config):\n",
        "    with open(filename, \"w\") as f:\n",
        "        json.dump(config, f, indent=4)\n",
        "\n",
        "\n",
        "start_time = time.time()\n",
        "\n",
        "if mount_drive:\n",
        "    if not os.path.exists(\"/content/drive/MyDrive\"):\n",
        "        print(\"\u001b[1;32mMounting google drive...\")\n",
        "        drive.mount(\"/content/drive\")\n",
        "          \n",
        "print(\"\u001b[1;32mInstalling...\\n\")\n",
        "with capture.capture_output() as cap:\n",
        "    !apt -y update -qq\n",
        "    !apt install libunwind8-dev -qq\n",
        "\n",
        "    ubuntu_deps(\n",
        "        \"https://huggingface.co/Linaqruf/fast-repo/resolve/main/deb-libs.zip\",\n",
        "        \"deb-libs.zip\",\n",
        "        deps_dir,\n",
        "    )\n",
        " \n",
        "    del cap\n",
        "\n",
        "if clean_install:\n",
        "    if os.path.exists(repo_dir):\n",
        "        print(\"\u001b[1;32mUninstall current Web UI...\")\n",
        "        shutil.rmtree(repo_dir)\n",
        "        pre_download()\n",
        "else:\n",
        "    if not os.path.exists(repo_dir):\n",
        "        pre_download()\n",
        "    else:\n",
        "        print(\"\u001b[1;32mAlready installed, skipping...\")\n",
        "\n",
        "if commit_hash:\n",
        "    try:\n",
        "        os.chdir(repo_dir)\n",
        "        with capture.capture_output() as cap:\n",
        "            !git reset --hard {commit_hash}\n",
        "            del cap\n",
        "        print(\"\u001b[1;32mCommit hash: \", commit_hash)\n",
        "    except Exception as e:\n",
        "        print(\"\u001b[1;32mAn error occurred while resetting the commit hash:\", e)\n",
        "\n",
        "if use_anapnoe_ui:\n",
        "    print(\"\u001b[1;32mUsing new UI/UX from @Anapnoe...\")\n",
        "    try:\n",
        "        os.chdir(repo_dir)\n",
        "        if stable_commit_hash:\n",
        "            try:\n",
        "                with capture.capture_output() as cap:\n",
        "                    !git reset --hard {stable_commit_hash}\n",
        "                del cap\n",
        "                print(\"\u001b[1;32mForce reset to Commit hash: \", stable_commit_hash)\n",
        "            except Exception as e:\n",
        "                print(\"\u001b[1;32mAn error occurred while resetting the commit hash:\", e)    \n",
        "\n",
        "\n",
        "        config = read_config(config_file)\n",
        "        if not \"stable-diffusion-webui\" in config[\"disabled_extensions\"]:\n",
        "            config[\"disabled_extensions\"].append(\"stable-diffusion-webui\")\n",
        "            config[\"disabled_extensions\"].append(\"stable-diffusion-webui-state\")\n",
        "            write_config(config_file, config)\n",
        "\n",
        "        with capture.capture_output() as cap:\n",
        "            !git remote set-url origin https://github.com/anapnoe/stable-diffusion-webui/\n",
        "            !git pull\n",
        "            del cap\n",
        "\n",
        "        if ui_commit_hash:\n",
        "            try:\n",
        "                with capture.capture_output() as cap:\n",
        "                    !git reset --hard {ui_commit_hash}\n",
        "                    del cap\n",
        "                print(\"\u001b[1;32mUI Commit hash: \", ui_commit_hash)\n",
        "            except Exception as e:\n",
        "                print(\"\u001b[1;32mAn error occurred while resetting the commit hash:\", e)\n",
        "    except Exception as e:\n",
        "        print(\"\u001b[1;32mAn error occurred:\", e)\n",
        "else:\n",
        "    config = read_config(config_file)\n",
        "    if \"stable-diffusion-webui\" in config[\"disabled_extensions\"]:\n",
        "        config[\"disabled_extensions\"].remove(\"stable-diffusion-webui\")\n",
        "        write_config(config_file, config)\n",
        "\n",
        "if git_pull:\n",
        "    try:\n",
        "        print(\"\u001b[1;32mUpdating Web UI to the latest version\")\n",
        "        with capture.capture_output() as cap:\n",
        "            os.chdir(repo_dir)\n",
        "            !git pull -X theirs --rebase --autostash\n",
        "        output = cap.stdout.strip()\n",
        "        if \"Already up to date.\" in output:\n",
        "            print(f\"\u001b[1;32mWeb UI is up to date\")\n",
        "    except Exception as e:\n",
        "        print(\"\u001b[1;32mAn error occurred when updating Web UI:\", e)\n",
        "\n",
        "with capture.capture_output() as cap:\n",
        "    !wget https://raw.githubusercontent.com/ddPn08/automatic1111-colab/main/patches/stablediffusion-lowram.patch -P {patches_dir}  -c\n",
        "    if load_v2_in_vram:\n",
        "        os.chdir(os.path.join(repo_dir, \"repositories/stable-diffusion-stability-ai\"))\n",
        "        !git apply {patches_dir}/stablediffusion-lowram.patch\n",
        "\n",
        "    if colab_optimizations:\n",
        "        !sed -i \"s@os.path.splitext(checkpoint_.*@os.path.splitext(checkpoint_file); map_location='cuda'@\" /content/stable-diffusion-webui/modules/sd_models.py\n",
        "        !sed -i 's@ui.create_ui().*@ui.create_ui();shared.demo.queue(concurrency_count=999999,status_update_rate=0.1)@' /content/stable-diffusion-webui/webui.py\n",
        "\n",
        "    if merge_in_vram:\n",
        "        !sed -i \"s@'cpu'@'cuda'@\" /content/stable-diffusion-webui/modules/extras.py\n",
        "    del cap\n",
        "\n",
        "if output_to_drive:\n",
        "    drive_dir = \"/content/drive/MyDrive/stable-diffusion-webui\"\n",
        "    if not os.path.exists(\"/content/drive/MyDrive\"):\n",
        "        print(\"\u001b[1;32mMounting google drive...\")\n",
        "        drive.mount(\"/content/drive\")\n",
        "else:\n",
        "    drive_dir = repo_dir\n",
        "\n",
        "config = read_config(config_file)\n",
        "config[\"outdir_txt2img_samples\"] = os.path.join(drive_dir, \"outputs/txt2img-images\")\n",
        "config[\"outdir_img2img_samples\"] = os.path.join(drive_dir, \"outputs/img2img-images\")\n",
        "config[\"outdir_extras_samples\"] = os.path.join(drive_dir, \"outputs/extras-images\")\n",
        "config[\"outdir_txt2img_grids\"] = os.path.join(drive_dir, \"outputs/txt2img-grids\")\n",
        "config[\"outdir_img2img_grids\"] = os.path.join(drive_dir, \"outputs/img2img-grids\")\n",
        "config[\"outdir_save\"] = os.path.join(drive_dir, \"log/images\")\n",
        "write_config(config_file, config)\n",
        "\n",
        "end_time = time.time()\n",
        "elapsed_time = int(end_time - start_time)\n",
        "\n",
        "if elapsed_time < 60:\n",
        "    print(f\"\u001b[1;32mFinished unpacking. Took {elapsed_time} sec\")\n",
        "else:\n",
        "    mins, secs = divmod(elapsed_time, 60)\n",
        "    print(f\"\u001b[1;32mFinished unpacking. Took {mins} mins {secs} sec\")\n",
        "\n",
        "if update_extensions:\n",
        "    start_time = time.time()\n",
        "    extensions_updated = []\n",
        "    with tqdm(\n",
        "        total=len(os.listdir(extensions_dir)),\n",
        "        desc=\"\u001b[1;32mUpdating extensions\",\n",
        "        mininterval=0,\n",
        "    ) as pbar:\n",
        "        for dir in os.listdir(extensions_dir):\n",
        "            if os.path.isdir(os.path.join(extensions_dir, dir)):\n",
        "                os.chdir(os.path.join(extensions_dir, dir))\n",
        "                try:\n",
        "                    with capture.capture_output() as cap:\n",
        "                        !git fetch origin\n",
        "                        !git pull\n",
        "                except Exception as e:\n",
        "                    print(f\"\u001b[1;32mAn error occurred while updating {dir}: {e}\")\n",
        "\n",
        "                output = cap.stdout.strip()\n",
        "                if \"Already up to date.\" not in output:\n",
        "                    extensions_updated.append(dir)\n",
        "                pbar.update(1)\n",
        "    print(\"\\n\")\n",
        "    for ext in extensions_updated:\n",
        "        print(f\"\u001b[1;32m- {ext} updated to new version\")\n",
        "\n",
        "    end_time = time.time()\n",
        "    elapsed_time = int(end_time - start_time)\n",
        "\n",
        "    if elapsed_time < 60:\n",
        "        print(f\"\\n\u001b[1;32mAll extensions are up to date. Took {elapsed_time} sec\")\n",
        "    else:\n",
        "        mins, secs = divmod(elapsed_time, 60)\n",
        "        print(f\"\\n\u001b[1;32mAll extensions are up to date. Took {mins} mins {secs} sec\")\n",
        "\n",
        "    \n",
        "os.environ['colab_url'] = eval_js(\"google.colab.kernel.proxyPort(7860, {'cache': false})\")\n",
        "os.environ[\"LD_PRELOAD\"] = \"libtcmalloc.so\"\n",
        "os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"3\"\n",
        "os.environ[\"SAFETENSORS_FAST_GPU\"]='1'  \n",
        "\n",
        "print(\"\u001b[1;32mAll is done! Go to the next step.\")"
      ],
      "metadata": {
        "id": "A6c7-qjDdb0X",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title ## **Download Model and VAE**\n",
        "import os\n",
        "import time\n",
        "from datetime import timedelta\n",
        "from IPython.utils import capture\n",
        "from tqdm import tqdm\n",
        "\n",
        "%store -r\n",
        "\n",
        "os.chdir(root_dir)\n",
        "# @markdown ### Available SD v1.x Model\n",
        "anything_v3_0 = True  # @param {type: 'boolean'}\n",
        "anime_pastel_dream = False  # @param {type: 'boolean'}\n",
        "anylora = True  # @param {type: 'boolean'}\n",
        "chilloutmix_ni = True  # @param {type: 'boolean'}\n",
        "stable_diffusion_v1_5 = True  # @param {type: 'boolean'}\n",
        "# @markdown ### Available SD v2.x 768v Model\n",
        "replicant_v1 = False  # @param {type: 'boolean'}\n",
        "illuminati_diffusion_v1_1 = True  # @param {type: 'boolean'}\n",
        "waifu_diffusion_v1_5_e2_aesthetic = True  # @param {type: 'boolean'}\n",
        "# @markdown ### Available VAE\n",
        "anime = True  # @param {type: 'boolean'}\n",
        "waifu_diffusion = True  # @param {type: 'boolean'}\n",
        "stable_diffusion = True  # @param {type: 'boolean'}\n",
        "\n",
        "downloadModels = []\n",
        "downloadVAE = []\n",
        "\n",
        "modelList = [\n",
        "    \"anything_v3_0\",\n",
        "    \"anime_pastel_dream\",\n",
        "    \"anylora\",\n",
        "    \"chilloutmix_ni\",\n",
        "    \"stable_diffusion_v1_5\",\n",
        "    \"replicant_v1\",\n",
        "    \"illuminati_diffusion_v1_1\",\n",
        "    \"waifu_diffusion_v1_5_e2_aesthetic\",\n",
        "]\n",
        "modelUrl = [\n",
        "    \"https://huggingface.co/AdamOswald1/Anything-Preservation/resolve/4121e81acc47bb87e46480ba1344b5ab57134b88/Anything-V3.0-pruned.safetensors\",\n",
        "    \"https://huggingface.co/Lykon/AnimePastelDream/resolve/main/AnimePastelDream_Soft_noVae_fp16.safetensors\",\n",
        "    \"https://huggingface.co/Lykon/AnyLoRA/resolve/main/AnyLoRA_noVae_fp16.safetensors\",\n",
        "    \"https://huggingface.co/naonovn/chilloutmix_NiPrunedFp32Fix/resolve/main/chilloutmix_NiPrunedFp32Fix.safetensors\",\n",
        "    \"https://huggingface.co/Linaqruf/stolen/resolve/main/pruned-models/stable_diffusion_1_5-pruned.safetensors\",\n",
        "    \"https://huggingface.co/gsdf/Replicant-V1.0/resolve/main/Replicant-V1.0_fp16.safetensors\",\n",
        "    \"https://huggingface.co/4eJIoBek/Illuminati-Diffusion-v1-1/resolve/main/illuminatiDiffusionV1_v11.safetensors\",\n",
        "    \"https://huggingface.co/waifu-diffusion/wd-1-5-beta2/resolve/main/checkpoints/wd-1-5-beta2-aesthetic-fp16.safetensors\",\n",
        "]\n",
        "\n",
        "vaeList = [\"anime\", \"waifu_diffusion\", \"stable_diffusion\"]\n",
        "\n",
        "vaeUrl = [\n",
        "    \"https://huggingface.co/Linaqruf/personal-backup/resolve/main/vae/animevae.pt\",\n",
        "    \"https://huggingface.co/hakurei/waifu-diffusion-v1-4/resolve/main/vae/kl-f8-anime.ckpt\",\n",
        "    \"https://huggingface.co/stabilityai/sd-vae-ft-mse-original/resolve/main/vae-ft-mse-840000-ema-pruned.ckpt\",\n",
        "]\n",
        "\n",
        "for i, model in enumerate(modelList):\n",
        "    if locals()[model]:  # if checkbox is checked\n",
        "        downloadModels.append((model, modelUrl[i]))\n",
        "\n",
        "for i, vae in enumerate(vaeList):\n",
        "    if locals()[vae]:  # if checkbox is checked\n",
        "        downloadVAE.append((vae, vaeUrl[i]))\n",
        "\n",
        "\n",
        "def download(checkpoint_name, url, is_vae=None, is_control=None):\n",
        "    basename = os.path.basename(url)\n",
        "    hf_token = \"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\"\n",
        "    user_header = f'\"Authorization: Bearer {hf_token}\"'\n",
        "    if is_vae:\n",
        "        !aria2c --console-log-level=error --summary-interval=10 --header={user_header} -c -x 16 -k 1M -s 16 -d {vaes_dir} -o {checkpoint_name}.vae.pt {url}\n",
        "    elif is_control:\n",
        "        !aria2c --console-log-level=error --summary-interval=10 --header={user_header} -c -x 16 -k 1M -s 16 -d {control_dir} -o {checkpoint_name} {url}\n",
        "    else:\n",
        "        if url.startswith(\"https://huggingface.co/\"):\n",
        "            ext = \"ckpt\" if url.endswith(\".ckpt\") else \"safetensors\"\n",
        "            !aria2c --console-log-level=error --summary-interval=10 --header={user_header} -c -x 16 -k 1M -s 16 -d {models_dir} -o {checkpoint_name}.{ext} {url}\n",
        "        else:\n",
        "            !aria2c --console-log-level=error --summary-interval=10 -c -x 16 -k 1M -s 16 -d {models_dir} {url}\n",
        "\n",
        "\n",
        "def main():\n",
        "    downloaded_model = []\n",
        "    downloaded_vae = []\n",
        "\n",
        "    for model in tqdm(downloadModels, desc=\"\u001b[1;32mDownloading Models\"):\n",
        "        with capture.capture_output() as cap:\n",
        "            download(model[0], model[1], is_vae=False)\n",
        "            downloaded_model.append(model[0])\n",
        "            del cap\n",
        "\n",
        "    for vae in tqdm(downloadVAE, desc=\"\u001b[1;32mDownloading VAE\"):\n",
        "        with capture.capture_output() as cap:\n",
        "            download(vae[0], vae[1], is_vae=True)\n",
        "            downloaded_vae.append(vae[0])\n",
        "            del cap\n",
        "\n",
        "print(f\"\u001b[1;32mDownloading...\")\n",
        "start_time = time.time()\n",
        "\n",
        "main()\n",
        "\n",
        "end_time = time.time()\n",
        "elapsed_time = int(end_time - start_time)\n",
        "\n",
        "if elapsed_time < 60:\n",
        "    print(f\"\\n\u001b[1;32mDownload completed. Took {elapsed_time} sec\")\n",
        "else:\n",
        "    mins, secs = divmod(elapsed_time, 60)\n",
        "    print(f\"\\n\u001b[1;32mDownload completed. Took {mins} mins {secs} sec\")\n",
        "\n",
        "print(\"\u001b[1;32mAll is done! Go to the next step\")"
      ],
      "metadata": {
        "id": "qgvihy5BQ3II",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title ## **ControlNet**\n",
        "import os\n",
        "import time\n",
        "from datetime import timedelta\n",
        "from IPython.utils import capture\n",
        "from tqdm import tqdm\n",
        "\n",
        "# @markdown ### ControlNet Annotator\n",
        "pre_download_annotator = True  # @param {type: 'boolean'}\n",
        "# @markdown ### SDv1.x ControlNet Model\n",
        "control_model = False  # @param {type: 'boolean'}\n",
        "diff_control_model = True  # @param {type: 'boolean'}\n",
        "t2i_adapter_model = False  # @param {type: 'boolean'}\n",
        "# @markdown ### SDv2.x ControlNet Model\n",
        "sd21_control_model = True  # @param {type: 'boolean'}\n",
        "wd15_control_model = False  # @param {type: 'boolean'}\n",
        "#@markdown ### ControlNet Config:\n",
        "control_net_max_models_num = 4 #@param {type:\"slider\", min:1, max:10, step:1}\n",
        "control_net_model_config = \"cldm_v15.yaml\" #@param [\"cldm_v15.yaml\", \"cldm_v21.yaml\"]\n",
        "control_net_model_adapter_config = \"sketch_adapter_v14.yaml\" #@param [\"image_adapter_v14.yaml\", \"sketch_adapter_v14.yaml\", \"t2iadapter_color_sd14v1.yaml\", \"t2iadapter_keypose_sd14v1.yaml\", \"t2iadapter_style_sd14v1.yaml\"]\n",
        "config_file = os.path.join(repo_dir, \"config.json\")\n",
        "\n",
        "# define the annotatorUrl and destination paths\n",
        "annotatorUrl = [\n",
        "    \"https://huggingface.co/ckpt/ControlNet/resolve/main/hand_pose_model.pth\",\n",
        "    \"https://huggingface.co/ckpt/ControlNet/resolve/main/body_pose_model.pth\",\n",
        "    \"https://huggingface.co/ckpt/ControlNet/resolve/main/dpt_hybrid-midas-501f0c75.pt\",\n",
        "    \"https://huggingface.co/ckpt/ControlNet/resolve/main/mlsd_large_512_fp32.pth\",\n",
        "    \"https://huggingface.co/ckpt/ControlNet/resolve/main/mlsd_tiny_512_fp32.pth\",\n",
        "    \"https://huggingface.co/ckpt/ControlNet/resolve/main/network-bsds500.pth\",\n",
        "    \"https://huggingface.co/ckpt/ControlNet/resolve/main/upernet_global_small.pth\"\n",
        "]\n",
        "\n",
        "annotatorPath = [\n",
        "    \"/content/stable-diffusion-webui/extensions/sd-webui-controlnet/annotator/openpose/hand_pose_model.pth\",\n",
        "    \"/content/stable-diffusion-webui/extensions/sd-webui-controlnet/annotator/openpose/body_pose_model.pth\",\n",
        "    \"/content/stable-diffusion-webui/extensions/sd-webui-controlnet/annotator/midas/dpt_hybrid-midas-501f0c75.pt\",\n",
        "    \"/content/stable-diffusion-webui/extensions/sd-webui-controlnet/annotator/mlsd/mlsd_large_512_fp32.pth\",\n",
        "    \"/content/stable-diffusion-webui/extensions/sd-webui-controlnet/annotator/mlsd/mlsd_tiny_512_fp32.pth\",\n",
        "    \"/content/stable-diffusion-webui/extensions/sd-webui-controlnet/annotator/hed/network-bsds500.pth\",\n",
        "    \"/content/stable-diffusion-webui/extensions/sd-webui-controlnet/annotator/uniformer/upernet_global_small.pth\"\n",
        "]\n",
        "\n",
        "controlUrl = [\n",
        "    \"https://huggingface.co/Linaqruf/stolen/resolve/main/controlnet-extracted-model/control_canny-fp16.safetensors\",\n",
        "    \"https://huggingface.co/Linaqruf/stolen/resolve/main/controlnet-extracted-model/control_depth-fp16.safetensors\",\n",
        "    \"https://huggingface.co/Linaqruf/stolen/resolve/main/controlnet-extracted-model/control_hed-fp16.safetensors\",\n",
        "    \"https://huggingface.co/Linaqruf/stolen/resolve/main/controlnet-extracted-model/control_mlsd-fp16.safetensors\",\n",
        "    \"https://huggingface.co/Linaqruf/stolen/resolve/main/controlnet-extracted-model/control_normal-fp16.safetensors\",\n",
        "    \"https://huggingface.co/Linaqruf/stolen/resolve/main/controlnet-extracted-model/control_openpose-fp16.safetensors\",\n",
        "    \"https://huggingface.co/Linaqruf/stolen/resolve/main/controlnet-extracted-model/control_scribble-fp16.safetensors\",\n",
        "    \"https://huggingface.co/Linaqruf/stolen/resolve/main/controlnet-extracted-model/control_seg-fp16.safetensors\",\n",
        "]\n",
        "\n",
        "diffControlUrl = [\n",
        "    \"https://huggingface.co/Linaqruf/stolen/resolve/main/controlnet-extracted-model/diff_control_sd15_canny_fp16.safetensors\",\n",
        "    \"https://huggingface.co/Linaqruf/stolen/resolve/main/controlnet-extracted-model/diff_control_sd15_depth_fp16.safetensors\",\n",
        "    \"https://huggingface.co/Linaqruf/stolen/resolve/main/controlnet-extracted-model/diff_control_sd15_hed_fp16.safetensors\",\n",
        "    \"https://huggingface.co/Linaqruf/stolen/resolve/main/controlnet-extracted-model/diff_control_sd15_mlsd_fp16.safetensors\",\n",
        "    \"https://huggingface.co/Linaqruf/stolen/resolve/main/controlnet-extracted-model/diff_control_sd15_normal_fp16.safetensors\",\n",
        "    \"https://huggingface.co/Linaqruf/stolen/resolve/main/controlnet-extracted-model/diff_control_sd15_openpose_fp16.safetensors\",\n",
        "    \"https://huggingface.co/Linaqruf/stolen/resolve/main/controlnet-extracted-model/diff_control_sd15_scribble_fp16.safetensors\",\n",
        "    \"https://huggingface.co/Linaqruf/stolen/resolve/main/controlnet-extracted-model/diff_control_sd15_seg_fp16.safetensors\",\n",
        "]\n",
        "\n",
        "t2iAdapterUrl = [\n",
        "    \"https://huggingface.co/webui/ControlNet-modules-safetensors/resolve/main/t2iadapter_canny-fp16.safetensors\",\n",
        "    \"https://huggingface.co/webui/ControlNet-modules-safetensors/resolve/main/t2iadapter_color-fp16.safetensors\",\n",
        "    \"https://huggingface.co/webui/ControlNet-modules-safetensors/resolve/main/t2iadapter_depth-fp16.safetensors\",\n",
        "    \"https://huggingface.co/webui/ControlNet-modules-safetensors/resolve/main/t2iadapter_keypose-fp16.safetensors\",\n",
        "    \"https://huggingface.co/webui/ControlNet-modules-safetensors/resolve/main/t2iadapter_openpose-fp16.safetensors\",\n",
        "    \"https://huggingface.co/webui/ControlNet-modules-safetensors/resolve/main/t2iadapter_seg-fp16.safetensors\",\n",
        "    \"https://huggingface.co/webui/ControlNet-modules-safetensors/resolve/main/t2iadapter_sketch-fp16.safetensors\",\n",
        "    \"https://huggingface.co/webui/ControlNet-modules-safetensors/resolve/main/t2iadapter_style-fp16.safetensors\",\n",
        "]\n",
        "\n",
        "sd21ControlUrl = [\n",
        "    \"https://huggingface.co/thibaud/controlnet-sd21/resolve/main/canny-sd21-safe.safetensors\",\n",
        "    \"https://huggingface.co/thibaud/controlnet-sd21/resolve/main/depth-sd21-safe.safetensors\",\n",
        "    \"https://huggingface.co/thibaud/controlnet-sd21/resolve/main/hed-sd21-safe.safetensors\",\n",
        "    \"https://huggingface.co/thibaud/controlnet-sd21/resolve/main/openpose-sd21-safe.safetensors\",\n",
        "    \"https://huggingface.co/thibaud/controlnet-sd21/resolve/main/scribble-sd21-safe.safetensors\",\n",
        "]\n",
        "\n",
        "wd15ControlUrl = [\n",
        "    \"https://huggingface.co/furusu/ControlNet/resolve/main/diff_control_wd15beta2_canny.safetensors\",\n",
        "    \"https://huggingface.co/furusu/ControlNet/resolve/main/diff_control_wd15beta2_depth.safetensors\",\n",
        "    \"https://huggingface.co/furusu/ControlNet/resolve/main/diff_control_wd15beta2_pose.safetensors\",\n",
        "]\n",
        "\n",
        "def read_config(filename):\n",
        "    with open(filename, \"r\") as f:\n",
        "      config = json.load(f)\n",
        "    return config\n",
        "\n",
        "\n",
        "def write_config(filename, config):\n",
        "    with open(filename, \"w\") as f:\n",
        "      json.dump(config, f, indent=4)\n",
        "\n",
        "\n",
        "def download(url, destination_path, is_annotator=None):\n",
        "    hf_token = \"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\"\n",
        "    user_header = f'\"Authorization: Bearer {hf_token}\"'\n",
        "    if is_annotator:\n",
        "        !aria2c --console-log-level=error --summary-interval=10 --header={user_header} -c -x 16 -k 1M -s 16 -d {os.path.dirname(destination_path)} -o {os.path.basename(destination_path)} {url}\n",
        "    else:\n",
        "        !aria2c --console-log-level=error --summary-interval=10 --header={user_header} -c -x 16 -k 1M -s 16 -d {control_dir} -o {os.path.basename(url)} {url}\n",
        "\n",
        "\n",
        "def batch(url, download_description, is_annotator=None):\n",
        "    if is_annotator:\n",
        "        for url, dest_path in tqdm(zip(annotatorUrl, annotatorPath), desc=f\"\u001b[1;32mDownloading {download_description}\"):\n",
        "            with capture.capture_output() as cap:\n",
        "                download(url, dest_path, is_annotator=True)\n",
        "                del cap\n",
        "    else:\n",
        "        for control in tqdm(url, desc=f\"\u001b[1;32mDownloading {download_description}\"):\n",
        "            with capture.capture_output() as cap:\n",
        "                download(control, download_description, is_annotator=False)\n",
        "                del cap\n",
        "\n",
        "\n",
        "def main():\n",
        "    config = read_config(config_file)\n",
        "    config[\"control_net_max_models_num\"] = control_net_max_models_num\n",
        "    config[\"control_net_model_config\"] = os.path.join(extensions_dir, os.path.join(\"sd-webui-controlnet/models\", control_net_model_config))\n",
        "    config[\"control_net_model_adapter_config\"] = os.path.join(extensions_dir, os.path.join(\"sd-webui-controlnet/models\", control_net_model_adapter_config))\n",
        "    config[\"control_net_models_path\"] = control_dir\n",
        "    config[\"control_net_allow_script_control\"] = True\n",
        "    write_config(config_file, config)\n",
        "  \n",
        "    if pre_download_annotator:\n",
        "        batch(annotatorUrl, \n",
        "              \"ControlNet Annotator/Preprocessor\", \n",
        "              is_annotator=True)\n",
        "              \n",
        "    if control_model:\n",
        "        batch(controlUrl, \n",
        "              \"SDv1.x ControlNet Model\", \n",
        "              is_annotator=False)\n",
        "        \n",
        "    if diff_control_model:\n",
        "        batch(diffControlUrl, \n",
        "              \"SDv1.x Difference ControlNet Model\", \n",
        "              is_annotator=False)\n",
        "        \n",
        "    if t2i_adapter_model:\n",
        "        batch(t2iAdapterUrl, \n",
        "              \"SDv1.x Text2Image Adapter Model\", \n",
        "              is_annotator=False)\n",
        "    \n",
        "    if sd21_control_model:\n",
        "        batch(sd21ControlUrl, \n",
        "              \"SDv2.x ControlNet Model\", \n",
        "              is_annotator=False)\n",
        "    \n",
        "    if wd15_control_model:\n",
        "        batch(wd15ControlUrl, \n",
        "              \"WD1.5 ControlNet Model\", \n",
        "              is_annotator=False)\n",
        "        \n",
        "\n",
        "print(f\"\u001b[1;32mDownloading...\")\n",
        "start_time = time.time()\n",
        "\n",
        "main()\n",
        "\n",
        "end_time = time.time()\n",
        "elapsed_time = int(end_time - start_time)\n",
        "\n",
        "if elapsed_time < 60:\n",
        "    print(f\"\\n\u001b[1;32mDownload completed. Took {elapsed_time} sec\")\n",
        "else:\n",
        "    mins, secs = divmod(elapsed_time, 60)\n",
        "    print(f\"\\n\u001b[1;32mDownload completed. Took {mins} mins {secs} sec\")\n",
        "\n",
        "print(\"\u001b[1;32mAll is done! Go to the next step\")"
      ],
      "metadata": {
        "cellView": "form",
        "id": "LKKtxDoIIg1T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title ## **Custom Download Corner**\n",
        "import os\n",
        "import shutil\n",
        "\n",
        "%store -r\n",
        "\n",
        "# @markdown Fill in the URL fields with the links to the files you want to download. Separate multiple URLs with a comma.\n",
        "# @markdown Example: `url1, url2, url3`\n",
        "os.chdir(root_dir)\n",
        "\n",
        "custom_download_list = []\n",
        "\n",
        "custom_model_url = \"/content/drive/MyDrive/AI/models/dreamlike-photoreal-2.0.ckpt\"  # @param {'type': 'string'}\n",
        "custom_vae_url = \"\"  # @param {'type': 'string'}\n",
        "custom_embedding_url = \"\"  # @param {'type': 'string'}\n",
        "custom_LoRA_url = \"\"  # @param {'type': 'string'}\n",
        "custom_hypernetwork_url = \"\"  # @param {'type': 'string'}\n",
        "custom_control_url = \"\"  # @param {'type': 'string'}\n",
        "custom_extensions_url = \"\"  # @param {'type': 'string'}\n",
        "custom_components_url = \"\"  # @param {'type': 'string'}\n",
        "custom_upscaler_url = \"\"  # @param {'type': 'string'}\n",
        "\n",
        "\n",
        "def extract(url, dst):\n",
        "    if not url.startswith(\"/content/\"):\n",
        "        filename = os.path.basename(url)\n",
        "        zipfile = os.path.join(dst, filename)\n",
        "    else:\n",
        "        zipfile = url\n",
        "\n",
        "    if url.endswith(\".zip\"):\n",
        "        if os.path.exists(zipfile):\n",
        "            !unzip -j -o {zipfile} -d \"{dst}\"\n",
        "            os.remove(zipfile)\n",
        "    elif url.endswith(\".tar.lz4\"):\n",
        "        if os.path.exists(zipfile):\n",
        "            !tar -xI lz4 -f {zipfile} --directory={dst}\n",
        "            os.remove(zipfile)\n",
        "    else:\n",
        "        pass\n",
        "\n",
        "\n",
        "def download(url_list, dst_dir, download_list, is_extensions):\n",
        "    downloaded = []\n",
        "    for url in tqdm(url_list, desc=\"\u001b[1;32mDownloading Custom URLs\"):\n",
        "        if url:\n",
        "            url = url.strip()\n",
        "            download_list.append(url)\n",
        "            basename = os.path.basename(url)\n",
        "\n",
        "            with capture.capture_output() as cap:\n",
        "                if is_extensions:\n",
        "                    os.chdir(extensions_dir)\n",
        "                    !git clone {url}\n",
        "                elif url.startswith(\"/content/drive/MyDrive/\"):\n",
        "                    shutil.copy(url, dst_dir)\n",
        "                elif url.startswith(\"https://drive.google.com\"):\n",
        "                    if \"folders\" in url:\n",
        "                        !gdown --folder \"{url}\" -O {dst_dir} --fuzzy -c\n",
        "                    else:\n",
        "                        !gdown \"{url}\" -O {dst_dir} --fuzzy -c\n",
        "                elif url.startswith(\"https://huggingface.co/\"):\n",
        "                    if \"/blob/\" in url:\n",
        "                        url = url.replace(\"/blob/\", \"/resolve/\")\n",
        "                    hf_token = \"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\"\n",
        "                    user_header = f'\"Authorization: Bearer {hf_token}\"'\n",
        "                    !aria2c --console-log-level=error --summary-interval=10 --header={user_header} -c -x 16 -k 1M -s 16 -d {dst_dir} -o {basename} {url}\n",
        "                else:\n",
        "                    !aria2c --console-log-level=error --summary-interval=10 -c -x 16 -k 1M -s 16 -d {dst_dir} {url}\n",
        "\n",
        "                extract(url, dst_dir)\n",
        "\n",
        "            del cap\n",
        "            downloaded.append((basename, dst_dir))\n",
        "\n",
        "\n",
        "custom_download_list = []\n",
        "\n",
        "custom_dirs = {\n",
        "    custom_model_url: models_dir,\n",
        "    custom_vae_url: vaes_dir,\n",
        "    custom_embedding_url: embeddings_dir,\n",
        "    custom_LoRA_url: lora_dir,\n",
        "    custom_hypernetwork_url: hypernetworks_dir,\n",
        "    custom_control_url: control_dir,\n",
        "    custom_extensions_url: extensions_dir,\n",
        "    custom_components_url: components_dir,\n",
        "    custom_upscaler_url: esrgan_dir,\n",
        "}\n",
        "\n",
        "print(f\"\u001b[1;32mDownloading...\")\n",
        "start_time = time.time()\n",
        "\n",
        "for custom_url in [\n",
        "    custom_model_url,\n",
        "    custom_vae_url,\n",
        "    custom_embedding_url,\n",
        "    custom_LoRA_url,\n",
        "    custom_hypernetwork_url,\n",
        "    custom_control_url,\n",
        "    custom_extensions_url,\n",
        "    custom_components_url,\n",
        "    custom_upscaler_url,\n",
        "]:\n",
        "    if custom_url:\n",
        "        urls = custom_url.split(\",\")\n",
        "        download(\n",
        "            urls,\n",
        "            custom_dirs[custom_url],\n",
        "            custom_download_list,\n",
        "            custom_url == custom_extensions_url,\n",
        "        )\n",
        "\n",
        "end_time = time.time()\n",
        "elapsed_time = int(end_time - start_time)\n",
        "\n",
        "if elapsed_time < 60:\n",
        "    print(f\"\\n\u001b[1;32mDownload completed. Took {elapsed_time} sec\")\n",
        "else:\n",
        "    mins, secs = divmod(elapsed_time, 60)\n",
        "    print(f\"\\n\u001b[1;32mDownload completed. Took {mins} mins {secs} sec\")\n",
        "\n",
        "print(\"\u001b[1;32mAll is done! Go to the next step\")"
      ],
      "metadata": {
        "id": "euzt0QG35aEO",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SaAJk33ppFw1",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@title ## **Start Stable Diffusion Web UI**\n",
        "import os\n",
        "import random\n",
        "%store -r \n",
        "\n",
        "# @markdown ### Gradio Auth\n",
        "user = \"\" # @param {type:\"string\"}\n",
        "password= \"\" # @param {type:\"string\"}\n",
        "\n",
        "# @markdown ### Alternative Tunnel\n",
        "alt_tunnel = \"multiple\" # @param ['none', 'multiple','cloudflared', 'localhostrun', 'remotemoe', \"googleusercontent\"]\n",
        "# @markdown > Get <b>your</b> token for ngrok [here](https://dashboard.ngrok.com/get-started/your-authtoken) \n",
        "ngrok_token = \"\" # @param {type: 'string'}\n",
        "ngrok_region = \"ap\" # @param [\"us\", \"eu\", \"au\", \"ap\", \"sa\", \"jp\", \"in\"]\n",
        "\n",
        "# @markdown ### Arguments\n",
        "medvram = False # @param {type: 'boolean'}\n",
        "load_in_vram = True # @param {type: 'boolean'}\n",
        "silent_launch = True # @param {type: 'boolean'}\n",
        "auto_model = False # @param {type: 'boolean'}\n",
        "auto_vae = True # @param {type: 'boolean'}\n",
        "no_half_vae = True # @param {type: 'boolean'}\n",
        "additional_args = \"--xformers\" #@param {type: 'string'}\n",
        "\n",
        "config_file = os.path.join(repo_dir, \"config.json\")\n",
        "ui_config_file = os.path.join(repo_dir, \"ui-config.json\")\n",
        "\n",
        "default_prompt = \"masterpiece, best quality,\"\n",
        "default_neg_prompt = \"(worst quality, low quality:1.4)\"\n",
        "default_sampler = \"DPM++ 2M Karras\"\n",
        "default_steps = 20\n",
        "default_width = 512\n",
        "default_height = 768\n",
        "default_denoising_strength = 0.55\n",
        "default_cfg_scale = 7\n",
        "\n",
        "def read_config(filename):\n",
        "    with open(filename, \"r\") as f:\n",
        "      config = json.load(f)\n",
        "    return config\n",
        "\n",
        "\n",
        "def write_config(filename, config):\n",
        "    with open(filename, \"w\") as f:\n",
        "      json.dump(config, f, indent=4)\n",
        "\n",
        "if auto_model:\n",
        "    models_list = os.listdir(models_dir)\n",
        "    model_files = [f for f in models_list if f.endswith(('.ckpt','.safetensors'))]\n",
        "    if model_files:\n",
        "        model_path = random.choice(model_files)\n",
        "\n",
        "if auto_vae:\n",
        "    vaes_list = os.listdir(vaes_dir)\n",
        "    vae_files = [f for f in vaes_list if f.endswith('.vae.pt')]\n",
        "    if vae_files:\n",
        "        vae_path = random.choice(vae_files)\n",
        "\n",
        "# config.json\n",
        "config = read_config(config_file)\n",
        "config[\"additional_networks_extra_lora_path\"] = lora_dir\n",
        "config[\"CLIP_stop_at_last_layers\"] = 2\n",
        "config[\"eta_noise_seed_delta\"] = 0\n",
        "config[\"show_progress_every_n_steps\"] = 10\n",
        "config[\"show_progressbar\"] = True\n",
        "if auto_model and os.path.exists(os.path.join(models_dir, model_path)):\n",
        "    config[\"sd_model_checkpoint\"] = model_path\n",
        "if auto_vae and os.path.exists(os.path.join(vaes_dir, vae_path)):\n",
        "    config[\"sd_vae\"] = vae_path\n",
        "config[\"quicksettings\"] = \"sd_model_checkpoint, sd_vae, CLIP_stop_at_last_layers, use_old_karras_scheduler_sigmas, always_discard_next_to_last_sigma\"\n",
        "write_config(config_file, config)\n",
        "\n",
        "# ui-config.json\n",
        "# txt2img\n",
        "config = read_config(ui_config_file)\n",
        "config[\"txt2img/Prompt/value\"] = default_prompt\n",
        "config[\"txt2img/Negative prompt/value\"] = default_neg_prompt\n",
        "config[\"txt2img/Sampling method/value\"] = default_sampler\n",
        "config[\"txt2img/Sampling steps/value\"] = default_steps\n",
        "config[\"txt2img/Width/value\"] = default_width\n",
        "config[\"txt2img/Height/value\"] = default_height\n",
        "config[\"txt2img/Upscaler/value\"] = \"Latent (nearest-exact)\"\n",
        "config[\"txt2img/Denoising strength/value\"] = default_denoising_strength\n",
        "config[\"txt2img/CFG Scale/value\"] = default_cfg_scale\n",
        "# img2img\n",
        "config[\"img2img/Prompt/value\"] = default_prompt\n",
        "config[\"img2img/Negative prompt/value\"] = default_neg_prompt\n",
        "config[\"img2img/Sampling method/value\"] = default_sampler\n",
        "config[\"img2img/Sampling steps/value\"] = default_steps\n",
        "config[\"img2img/Width/value\"] = default_width\n",
        "config[\"img2img/Height/value\"] = default_height\n",
        "config[\"img2img/Denoising strength/value\"] = default_denoising_strength\n",
        "config[\"img2img/CFG Scale/value\"] = default_cfg_scale\n",
        "write_config(ui_config_file, config)\n",
        "          \n",
        "os.chdir(repo_dir)\n",
        "\n",
        "print(\"\u001b[1;32m\")\n",
        "\n",
        "!python launch.py \\\n",
        "    --enable-insecure-extension-access \\\n",
        "    --disable-safe-unpickle \\\n",
        "    {\"--\" + alt_tunnel if not alt_tunnel == \"none\" and not ngrok_token else \"\"} \\\n",
        "    {\"--medvram\" if medvram else \"\"} \\\n",
        "    {\"--share\" if not ngrok_token else \"\"} \\\n",
        "    {\"--gradio-auth \" + user + \":\" + password if user and password else \"\"} \\\n",
        "    {\"--no-half-vae\" if no_half_vae else \"\"} \\\n",
        "    {\"--lowram\" if load_in_vram else \"\"} \\\n",
        "    {\"--no-hashing\" if silent_launch else \"\"} \\\n",
        "    {\"--disable-console-progressbars\" if silent_launch else \"\"} \\\n",
        "    {\"--ngrok \" + ngrok_token if ngrok_token else \"\"} \\\n",
        "    {\"--ngrok-region \" + ngrok_region if ngrok_token else \"\"} \\\n",
        "    --gradio-queue \\\n",
        "    --opt-sub-quad-attention \\\n",
        "    --opt-channelslast \\\n",
        "    --theme dark \\\n",
        "    {additional_args}"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title ## **Download Generated Images**\n",
        "# @markdown Download file manually from files tab or save to Google Drive\n",
        "import os\n",
        "from pydrive.auth import GoogleAuth\n",
        "from google.colab import drive\n",
        "from pydrive.drive import GoogleDrive\n",
        "from google.colab import auth\n",
        "from oauth2client.client import GoogleCredentials\n",
        "\n",
        "%store -r\n",
        "\n",
        "os.chdir(outputs_dir)\n",
        "\n",
        "use_drive = True  # @param {type:\"boolean\"}\n",
        "folder_name = \"AI-generated Art\"  # @param {type: \"string\"}\n",
        "filename = \"waifu.zip\"  # @param {type: \"string\"}\n",
        "save_as = filename\n",
        "\n",
        "if os.path.exists(filename):\n",
        "    i = 1\n",
        "    while os.path.exists(f\"waifu({i}).zip\"):\n",
        "        i += 1\n",
        "    filename = f\"waifu({i}).zip\"\n",
        "\n",
        "!zip -r /content/outputs.zip .\n",
        "\n",
        "if use_drive:\n",
        "    auth.authenticate_user()\n",
        "    gauth = GoogleAuth()\n",
        "    gauth.credentials = GoogleCredentials.get_application_default()\n",
        "    drive = GoogleDrive(gauth)\n",
        "\n",
        "    def create_folder(folder_name):\n",
        "        file_list = drive.ListFile(\n",
        "            {\n",
        "                \"q\": \"title='{}' and mimeType='application/vnd.google-apps.folder' and trashed=false\".format(\n",
        "                    folder_name\n",
        "                )\n",
        "            }\n",
        "        ).GetList()\n",
        "        if len(file_list) > 0:\n",
        "            print(\"Debug: Folder exists\")\n",
        "            folder_id = file_list[0][\"id\"]\n",
        "        else:\n",
        "            print(\"Debug: Creating folder\")\n",
        "            file = drive.CreateFile(\n",
        "                {\"title\": folder_name, \"mimeType\": \"application/vnd.google-apps.folder\"}\n",
        "            )\n",
        "            file.Upload()\n",
        "            folder_id = file.attr[\"metadata\"][\"id\"]\n",
        "        return folder_id\n",
        "\n",
        "    def upload_file(file_name, folder_id, save_as):\n",
        "        file_list = drive.ListFile(\n",
        "            {\"q\": \"title='{}' and trashed=false\".format(save_as)}\n",
        "        ).GetList()\n",
        "        if len(file_list) > 0:\n",
        "            print(\"Debug: File already exists\")\n",
        "            i = 1\n",
        "            while True:\n",
        "                new_name = (\n",
        "                    os.path.splitext(save_as)[0]\n",
        "                    + f\"({i})\"\n",
        "                    + os.path.splitext(save_as)[1]\n",
        "                )\n",
        "                file_list = drive.ListFile(\n",
        "                    {\"q\": \"title='{}' and trashed=false\".format(new_name)}\n",
        "                ).GetList()\n",
        "                if len(file_list) == 0:\n",
        "                    save_as = new_name\n",
        "                    break\n",
        "                i += 1\n",
        "        file = drive.CreateFile({\"title\": save_as, \"parents\": [{\"id\": folder_id}]})\n",
        "        file.SetContentFile(file_name)\n",
        "        file.Upload()\n",
        "        file.InsertPermission({\"type\": \"anyone\", \"value\": \"anyone\", \"role\": \"reader\"})\n",
        "        return file.attr[\"metadata\"][\"id\"]\n",
        "\n",
        "    file_id = upload_file(\"/content/outputs.zip\", create_folder(folder_name), save_as)\n",
        "    print(\n",
        "        \"Your sharing link: https://drive.google.com/file/d/\"\n",
        "        + file_id\n",
        "        + \"/view?usp=sharing\"\n",
        "    )"
      ],
      "metadata": {
        "cellView": "form",
        "id": "Ojb4nAieATxI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Extras"
      ],
      "metadata": {
        "id": "4SUHPtGLz2m4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# @title ## **Download Generated Images V2**\n",
        "from IPython.utils import capture\n",
        "from huggingface_hub import login\n",
        "from huggingface_hub import HfApi\n",
        "from huggingface_hub.utils import validate_repo_id, HfHubHTTPError\n",
        "import shutil\n",
        "import os\n",
        "\n",
        "# @markdown Download your output by upload it to **Huggingface** instead of Google Drive.\n",
        "# @markdown > Get **your** huggingface `WRITE` token [here](https://huggingface.co/settings/tokens)\n",
        "write_token = \"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\"  # @param {type:\"string\"}\n",
        "# @markdown Specify where is your repo located, it will automatically create your repo if you didn't have one.\n",
        "repo_name = \"\"  # @param{type:\"string\"}\n",
        "repo_name = repo_name.replace(\" \", \"-\")\n",
        "private_repo = False  # @param{type:\"boolean\"}\n",
        "# @markdown This will be compressed to zip and uploaded to datasets repo\n",
        "project_name = \"waifu\"  # @param {type :\"string\"}\n",
        "project_name = project_name.replace(\" \", \"_\")\n",
        "\n",
        "if not project_name:\n",
        "    project_name = \"waifu\"\n",
        "\n",
        "output_dir = \"/content/stable-diffusion-webui/outputs\"\n",
        "dataset_zip = project_name + \".zip\"\n",
        "output_path = os.path.join(root_dir, dataset_zip)\n",
        "commit_message = \"Feat: Upload \" + dataset_zip + \" with Cagliostro Colab UI\"\n",
        "\n",
        "with capture.capture_output() as cap:\n",
        "    login(write_token, add_to_git_credential=True)\n",
        "output = cap.stdout.strip()\n",
        "if \"Token is valid.\" in output:\n",
        "    print(\"\u001b[1;32mLogin Succesful.\")\n",
        "\n",
        "api = HfApi()\n",
        "user = api.whoami(write_token)\n",
        "\n",
        "datasets_repo = user[\"name\"] + \"/\" + repo_name.strip()\n",
        "\n",
        "if repo_name:\n",
        "    try:\n",
        "        validate_repo_id(datasets_repo)\n",
        "        api.create_repo(\n",
        "            repo_id=datasets_repo, repo_type=\"dataset\", private=private_repo\n",
        "        )\n",
        "        print(\n",
        "            f\"\u001b[1;32mRepo created, located at https://huggingface.co/datasets/{datasets_repo}\"\n",
        "        )\n",
        "\n",
        "    except HfHubHTTPError as e:\n",
        "        print(f\"\u001b[1;32mRepo exist, skipping...\")\n",
        "\n",
        "os.chdir(output_dir)\n",
        "print(f\"\u001b[1;32mCompressing to ZIP...\")\n",
        "with capture.capture_output() as cap:\n",
        "    !zip -rv {output_path} .\n",
        "\n",
        "print(f\"\u001b[1;32mUploading generated images... Please wait...\")\n",
        "\n",
        "api.upload_file(\n",
        "    path_or_fileobj=output_path,\n",
        "    path_in_repo=dataset_zip,\n",
        "    repo_id=datasets_repo,\n",
        "    repo_type=\"dataset\",\n",
        "    commit_message=commit_message,\n",
        ")\n",
        "\n",
        "print(\n",
        "    f\"\u001b[1;32mUpload success, download directly at https://huggingface.co/datasets/{datasets_repo}/resolve/main/{dataset_zip}\"\n",
        ")\n",
        "\n",
        "os.remove(output_path)"
      ],
      "metadata": {
        "id": "EGXqJLXwnJQB"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "include_colab_link": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}